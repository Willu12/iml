{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64bb948c",
   "metadata": {},
   "source": [
    "# Measuring Model Uncertainty\n",
    "Uncertainty in machine learning stems from the inherent unpredictability of real-world data and the limitations of models in capturing all its complexities. Effectively understanding and managing this uncertainty is crucial for successful machine learning applications. In this notebook, we will assess the uncertainty of the OriginalSizeDropoutCNN model using two techniques: ***Monte Carlo Dropout*** and an ***Ensemble of models***. We will then compare the results from both methods to evaluate their effectiveness in quantifying model uncertainty.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ca4b2b5ba7c129",
   "metadata": {},
   "source": [
    "# Set up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./notebooks\"):\n",
    "    %cd ..\n",
    "\n",
    "import numpy as np\n",
    "from src.data_processing import load_mean_std\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import src.model\n",
    "from src.training import monte_carlo_predictions, model_validate\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb971ae6",
   "metadata": {},
   "source": [
    "# 0. Set Device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4ce85b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd782715",
   "metadata": {},
   "source": [
    "# Monte Carlo Dropout\n",
    "Monte Carlo (MC) Dropout is a technique used to estimate model uncertainty by applying dropout during both training and inference. By performing multiple stochastic forward passes with different neurons dropped each time, we can approximate a distribution over the model's predictions, revealing its uncertainty. To achieve this we will process the sama data through the model with dropout turned on."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fcfe3972985dc652",
   "metadata": {},
   "source": [
    "# 1. Define Monte Carlo Dropout testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f714a59f6ff3b6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_dropout(model, test_loader, samples = 20):\n",
    "    predictions = []\n",
    "    for _ in range(samples):\n",
    "        predictions.append(monte_carlo_predictions(model, test_loader))\n",
    "        \n",
    "    predictions = np.stack(predictions , 0)\n",
    "    mean_predictions = np.mean(predictions, axis=0)\n",
    "    entropy = -1.0  * np.sum(mean_predictions * np.log(mean_predictions + 1e-16), axis=-1)\n",
    "    return predictions, entropy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96671c114914dc76",
   "metadata": {},
   "source": [
    "## Load Models\n",
    "We will compare the results obtained from Monte Carlo Dropout with those from 10 instances of the OriginalSizeCNN model, each trained independently with different initial weights. All models were trained on the same data, providing a basis for evaluating the uncertainty in predictions across different training runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4626f4dbd4be01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, name) :\n",
    "    model_path = f\"./models/{name}.pth\"\n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True,map_location=torch.device(device)))\n",
    "    model.device = device\n",
    "    model.to(device)\n",
    "\n",
    "def load_dropout_model(model : src.model.DropoutCNN, name, p_cnl = 0.5, p_fl = 0.15):\n",
    "    load_model(model,name)\n",
    "    model.dropoutCNL.p = p_cnl\n",
    "    model.dropoutFL.p = p_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e79eddf294d4088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import prepare_dataset_loaders\n",
    "from src.config import DATASET_DIR \n",
    "mean, std = load_mean_std(f\"{DATASET_DIR}/scaling_params.json\")\n",
    "\n",
    "dropout_model = src.model.DropoutCNN() \n",
    "load_model(dropout_model, \"DropoutCNN\")\n",
    "\n",
    "dropout_models = []\n",
    "dropout_parameters = [(0.5, 0.15), (0.7, 0.3), (0.8,0.5)]\n",
    "for (cnl_p, fl_p) in dropout_parameters:\n",
    "    dropout_model = src.model.DropoutCNN() \n",
    "    load_dropout_model(dropout_model,\"DropoutCNN\",  cnl_p, fl_p)\n",
    "    dropout_models.append(dropout_model)\n",
    "\n",
    "ensemble_models = []\n",
    "\n",
    "for i in range(10):\n",
    "    sample_model = src.model.OriginalSizeCNN()\n",
    "    model_name = f\"Ensemble/OriginalSizeCNN_{i}\"\n",
    "    load_model(sample_model, model_name)\n",
    "    ensemble_models.append(sample_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1e27020e15a775d",
   "metadata": {},
   "source": [
    "## 4. Get predictions from models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50767b42a575e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10 \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "mc_dropout_preditctions = []\n",
    "mc_dropout_entropies = []\n",
    "mc_dropout_variances = []\n",
    "\n",
    "train_loader, val_loader, test_loader = prepare_dataset_loaders(transform, batch_size)\n",
    "\n",
    "for model in dropout_models:\n",
    "    predictions, entropy = monte_carlo_dropout(model, test_loader, samples=15)\n",
    "    mc_dropout_entropies.append(entropy)\n",
    "    mc_dropout_preditctions.append(predictions)\n",
    "    mc_dropout_variances.append(np.var(predictions, axis=0))\n",
    "\n",
    "ensemble_predictions = []\n",
    "for model in ensemble_models:\n",
    "    preds, _ = model_validate(model, test_loader)\n",
    "    ensemble_predictions.append(preds)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e54546b4",
   "metadata": {},
   "source": [
    "## 5. Measures of Uncertainty\n",
    "We will measure the uncertainty of the model by calculating the variance and entropy of predictions both for MC dropout and Ensemble of models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "360ae0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics of MC dropout model with dropout on CNL = 0.5  FL = 0.15\n",
      "Mean variance  0.0842933879135557\n",
      "Entropy:  1643.278389332923\n",
      "Statistics of MC dropout model with dropout on CNL = 0.7  FL = 0.3\n",
      "Mean variance  0.15945035409880173\n",
      "Entropy:  2993.2203554656685\n",
      "Statistics of MC dropout model with dropout on CNL = 0.8  FL = 0.5\n",
      "Mean variance  0.19597912883046498\n",
      "Entropy:  3640.0800428652565\n",
      "Mean variance of Ensemble model: 0.030346795814235064\n",
      "Ensemble Entropy: None\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_entropy(predictions):\n",
    "    -1.0  * np.sum(np.mean(predictions,axis=0) * np.log(np.mean(predictions,axis=0) + 1e-16), axis=-1);\n",
    "\n",
    "ensemble_variances = np.var(ensemble_predictions, axis=0)\n",
    "ensemble_entropy = calculate_entropy(ensemble_predictions)\n",
    "\n",
    "for i in range(len(dropout_models)):\n",
    "    print(f\"Statistics of MC dropout model with dropout on CNL = {dropout_parameters[i][0]}  FL = {dropout_parameters[i][1]}\")\n",
    "    print(\"Mean variance \", np.mean(mc_dropout_variances[i]))\n",
    "    print(\"Entropy: \", mc_dropout_entropies[i])\n",
    "\n",
    "print(\"Mean variance of Ensemble model:\", np.mean(ensemble_variances))\n",
    "print(\"Ensemble Entropy:\", ensemble_entropy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ed0430a",
   "metadata": {},
   "source": [
    "The Monte Carlo (MC) Dropout models with higher dropout rates (CNL and FL) show increasing variance and entropy, indicating higher model uncertainty. Specifically, the model with a dropout rate of 0.8 on CNL and 0.5 on FL has the highest variance (0.196) and entropy (3640.08). In comparison, the Ensemble model exhibits a much lower variance of 0.0303, suggesting it is more stable and less uncertain. The higher variance and entropy in the MC dropout models imply that they explore different regions of the solution space, while the Ensemble model provides more reliable predictions with less uncertainty."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "284ec5d28c172321",
   "metadata": {},
   "source": [
    "## 6. Compare results of Monte Carlo dropout to Ensemble of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a8672f13faaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "dropout_flattened = [pred.flatten() for pred in mc_dropout_preditctions[0]]  \n",
    "ensemble_flattened = [np.array(pred).flatten() for pred in ensemble_predictions] \n",
    "comparison_matrix = np.zeros((10, 10))\n",
    "\n",
    "for i in range(10): \n",
    "    for j in range(10):  \n",
    "        correlation, _ = pearsonr(dropout_flattened[i], ensemble_flattened[j])\n",
    "        comparison_matrix[i, j] = correlation  \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(comparison_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Monte Carlo Dropout vs Ensemble Predictions\")\n",
    "plt.xlabel(\"Ensemble Model Index\")\n",
    "plt.ylabel(\"Dropout Pass Index\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d0c6afa",
   "metadata": {},
   "source": [
    "# Plot Monte Carlo Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aa30a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Predicted Probabilities\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(dropout_mean_predictions, bins=30, kde=True, color='blue')\n",
    "plt.title(\"Distribution of Predicted Probabilities for Dropout Model\")\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(dropout_variance_predictions, bins=30, kde=True, color='blue')\n",
    "plt.title(\"Distribution of Variances for Dropout Model\")\n",
    "plt.xlabel(\"Variance\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f775c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pairwise variance for MC Dropout runs\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mc_dropout_variances = np.var(dropout_predictions, axis=0)\n",
    "\n",
    "# Compute pairwise variance for ensemble models\n",
    "ensemble_predictions_array = np.stack(ensemble_predictions, axis=0)  # Shape: (10, num_samples, num_classes)\n",
    "ensemble_variances = np.var(ensemble_predictions_array, axis=0)\n",
    "\n",
    "print(\"Average Variance (MC Dropout):\", np.mean(mc_dropout_variances))\n",
    "print(\"Average Variance (Ensemble):\", np.mean(ensemble_variances))\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Combine predictions for visualization\n",
    "# Combine individual predictions for visualization\n",
    "all_predictions = np.vstack([\n",
    "    dropout_predictions.reshape(-1, dropout_predictions.shape[-1]),  # All MC Dropout predictions\n",
    "    np.vstack(ensemble_predictions)  # All Ensemble predictions\n",
    "])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "all_predictions_normalized = scaler.fit_transform(all_predictions)\n",
    "\n",
    "# Apply t-SNE\n",
    "embedded = TSNE(n_components=2, perplexity=min(30, all_predictions_normalized.shape[0] - 1)).fit_transform(all_predictions_normalized)\n",
    "\n",
    "\n",
    "# Plot\n",
    "plt.scatter(embedded[:10, 0], embedded[:10, 1], label=\"MC Dropout\", color=\"blue\")\n",
    "plt.scatter(embedded[10:, 0], embedded[10:, 1], label=\"Ensemble\", color=\"red\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss Landscape (t-SNE Projection)\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "cccc1e4ed51fc8b9fd510a52ec83f3ba6504ae6c1f28f1731113cc11ad46be9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
