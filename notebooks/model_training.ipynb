{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this cell to set up paths, imports, and W&B logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mytkom/Documents/iml\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import wandb\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from src.model import SimpleCNN\n",
    "from src.training import train, validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initialize W&B project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmytkom\u001b[0m (\u001b[33mmytkom-warsaw-university-of-technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mytkom/Documents/iml/wandb/run-20241030_160553-kah8gqq3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mytkom-warsaw-university-of-technology/speech_recognition/runs/kah8gqq3' target=\"_blank\">bewitched-scarecrow-2</a></strong> to <a href='https://wandb.ai/mytkom-warsaw-university-of-technology/speech_recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mytkom-warsaw-university-of-technology/speech_recognition' target=\"_blank\">https://wandb.ai/mytkom-warsaw-university-of-technology/speech_recognition</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mytkom-warsaw-university-of-technology/speech_recognition/runs/kah8gqq3' target=\"_blank\">https://wandb.ai/mytkom-warsaw-university-of-technology/speech_recognition/runs/kah8gqq3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RUN_NAME=\"SimpleCNN_1\"\n",
    "\n",
    "wandb.init(name=\"\", project=\"iml\", config={\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": 80,\n",
    "    \"batch_size\": 32,\n",
    "    \"image_size\": (32, 32)\n",
    "})\n",
    "config = wandb.config\n",
    "\n",
    "# Configure directories\n",
    "TRAIN_DIR = \"./datasets/train/\"\n",
    "VAL_DIR = \"./datasets/val/\"\n",
    "TEST_DIR = \"./datasets/test/\"\n",
    "\n",
    "# Speakers of such labels should be admitted to enter\n",
    "VALID_ACCESS_LABELS = {\n",
    "    \"f1\", \"f7\", \"f8\", \"m3\", \"m6\", \"m8\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define a custom dataset class to load spectrograms from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.png')]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.files[idx]\n",
    "        speaker_id = img_path.split('/')[-1].split('_')[0]\n",
    "        label = int(speaker_id in VALID_ACCESS_LABELS)\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Set up data transformations and data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(config.image_size),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = SpectrogramDataset(TRAIN_DIR, transform=transform)\n",
    "val_dataset = SpectrogramDataset(VAL_DIR, transform=transform)\n",
    "test_dataset = SpectrogramDataset(TEST_DIR, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 4. Initialize model, optimizer, and set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN(num_classes=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training and validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Train Loss:  0.6292004585266113 , Epoch:  0\n",
      "{'Validation F1': np.float64(0.382804995196926)}\n",
      "Epoch 2/3\n",
      "Train Loss:  0.40982311964035034 , Epoch:  1\n",
      "{'Validation F1': np.float64(0.7060663517558026)}\n",
      "Epoch 3/3\n",
      "Train Loss:  0.4516843259334564 , Epoch:  2\n",
      "{'Validation F1': np.float64(0.8228201697494613)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(config.epochs):\n",
    "    print(f\"Epoch {epoch+1}/{config.epochs}\")\n",
    "    \n",
    "    train_loss = train(model, train_loader, optimizer, epoch)\n",
    "    val_f1 = validate(model, val_loader)\n",
    "    wandb.log({\"Train Loss\": train_loss, \"Validation F1\": val_f1, \"Epoch\": epoch+1})\n",
    "    print(\"Train Loss: \", train_loss, \", Validation F1\", val_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 6. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▃▃▆▆█</td></tr><tr><td>Train Loss</td><td>█▁▂</td></tr><tr><td>Validation F1</td><td>▁▁▆▆██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>3</td></tr><tr><td>Validation F1</td><td>0.82282</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bewitched-scarecrow-2</strong> at: <a href='https://wandb.ai/mytkom-warsaw-university-of-technology/speech_recognition/runs/kah8gqq3' target=\"_blank\">https://wandb.ai/mytkom-warsaw-university-of-technology/speech_recognition/runs/kah8gqq3</a><br/> View project at: <a href='https://wandb.ai/mytkom-warsaw-university-of-technology/speech_recognition' target=\"_blank\">https://wandb.ai/mytkom-warsaw-university-of-technology/speech_recognition</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241030_160553-kah8gqq3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete and model saved!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_path = \"./models/simple_cnn.pth\"\n",
    "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "torch.save(model.state_dict(), model_path)\n",
    "wandb.save(model_path)\n",
    "wandb.finish()\n",
    "\n",
    "print(\"Training complete and model saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
