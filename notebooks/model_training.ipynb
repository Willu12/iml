{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this cell to set up paths, imports, and W&B logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import wandb\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "import src.model\n",
    "from src.training import train, validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize W&B project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"iml\", config={\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": 80,\n",
    "    \"batch_size\": 32,\n",
    "    \"image_size\": (32, 32) # TODO: choose best image_size\n",
    "})\n",
    "config = wandb.config\n",
    "\n",
    "# Configure directories\n",
    "TRAIN_DIR = \"./datasets/train/\"\n",
    "VAL_DIR = \"./datasets/val/\"\n",
    "TEST_DIR = \"./datasets/test/\"\n",
    "\n",
    "# Speakers of such labels should be admitted to enter\n",
    "VALID_ACCESS_LABELS = {\n",
    "    \"f1\", \"f7\", \"f8\", \"m3\", \"m6\", \"m8\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define a custom dataset class to load spectrograms from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.png')]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.files[idx]\n",
    "        speaker_id = img_path.split('/')[-1].split('_')[0]\n",
    "        label = int(speaker_id in VALID_ACCESS_LABELS)\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set up data transformations and data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(config.image_size),\n",
    "    transforms.ToTensor(),\n",
    "    # TODO: normalization\n",
    "])\n",
    "\n",
    "train_dataset = SpectrogramDataset(TRAIN_DIR, transform=transform)\n",
    "val_dataset = SpectrogramDataset(VAL_DIR, transform=transform)\n",
    "test_dataset = SpectrogramDataset(TEST_DIR, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize model, optimizer, and set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = src.model.SimpleCNN().to(device)\n",
    "model = src.model.TutorialCNN() # - for 32x32 images\n",
    "model.device = device\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training and validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(config.epochs):\n",
    "    print(f\"Epoch {epoch+1}/{config.epochs}\")\n",
    "    \n",
    "    train(model, train_loader, criterion, optimizer, epoch, wandb.log, len(train_loader) // 5 - 1)\n",
    "    recall, precision, val_f1 = validate(model, val_loader)\n",
    "    wandb.log({\"validation/recall\": recall, \"validation/precision\": precision, \"validation/f1\": val_f1, \"epoch\": epoch+1})\n",
    "    print(\"Recall: \", recall, \", Precision: \", precision, \", Validation F1: \", val_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path = \"./models/simple_cnn.pth\"\n",
    "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "torch.save(model.state_dict(), model_path)\n",
    "wandb.save(model_path)\n",
    "wandb.finish()\n",
    "\n",
    "print(\"Training complete and model saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
